Outlining a short course on web scraping...

# Human parallels
We can theatrically perform a system for acquiring data with
and without using computers

* distinguishing between receiving (downloading) and reading (parsing)
* assertion that the process doesn't change much when you
    switch humans for computers
* discussion of how to develop the computer process iteratively

## Concepts

1. Download a web page (HTTP)
2. Save results for reproducability
3. Read file formats (HTML, JSON, Javascript, RSS)
4. Save the data as a table

## Libraries you want

* HTTP client
* Storage of some sort (for example, files)
* Fancy parsers
  * HTML/XML, XPath, CSS
  * JSON
* General parsers
  * Regular expressions
  * strptime
* PDFs and images
  * http://thomaslevine.com/!/parsing-pdfs
  * https://www.meetup.com/Data-Wranglers-DC/events/160592492/
