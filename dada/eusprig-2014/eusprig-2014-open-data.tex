% Adjustments
% ===========


% \subsection{Existing means of understanding a lot of spreadsheets}
% We could manually look at every cell in every spreadsheet,
% but this would take a long time. Instead, we develop tools,
% and standard practices to make this a bit easier.

% Many "open data" guidelines provide direction as to how a person
% or organization with lots of spreadsheets might allow other people
% to use them. At a basic level, many guidelines suggest that data
% be available on the internet and under a free license; at the other
% end of the spectrum, guidelines suggest that data be in standard
% formats accompanied with assorted metadata.

% Many groups have developed standard schemas for particular sorts
% of data. examples (cite stuff)

% \subsection{Things that don't exist but maybe should}
% The various tools that I describe above assist in understanding
% individual spreadsheets. What if we have a million spreadsheets?
% Even if we have the most perfect graphs about each separate spreadsheet,
% we won't have time to look at them all; we need to narrow down
% the spreadsheet base before we look at them

% It's like the concept of information retrieval and the-other-thing

% but I think we can take a qualitatively
% different approach to understanding 


% search engine

% stats for search engine (pagerank for spreadsheets)



% -- Do I need this part?
% People want to share spreadsheets with each other (citations).
% People, governments, and other organizations even want to share spreadsheets and with the
% entire world, and they often call this "open data".
% In either case, this might intuitively seem like a good idea;
% this can enable a wide range of people to perform new sorts of analysis.

% 

\documentclass{acm_proc_article-sp}
\usepackage{url}
\begin{document}
\title{How can we figure out what is inside thousands of spreadsheets?}
\numberofauthors{1}
\author{ \alignauthor Thomas Levine\\ \email{\_@thomaslevine.com} }
\date{6 March 2014}
\maketitle
\begin{abstract}
I have been exploring methods for understanding the contents
of thousands of spreadsheets at once. I will discuss strategies for automatically
assessing the usability of spreadsheets, the quality of data
in spreadsheets, and the relevance of specific spreadsheets to particular
analysis questions; I will explain both how these methods work and how they
can help you analyze and manage your spreadsheets.
\end{abstract}

\keywords{data management, spreadsheets, open data, search}

\section{Introduction}
These days, we have more data than we know what to do with. And by "data",
we often mean unclean, poorly documented spreadsheets. How are we to have
any idea what these millions of spreadsheets contain? In my research,
I search for approaches to understanding the contents of large collections
of weakly structured spreadsheets.

\section{Typical approaches to exploring the contents of spreadsheets}
Before we discuss my spreadsheet exploration methods,
let's consider some more common approaches.
How do we figure out what's in a bunch of spreadsheets today?

\subsection{Look at every spreadsheet}
One approach is to look manually at every cell in many spreadsheets.
This takes a long time, but it is feasible in some situations.

For example, the Open Knowledge Foundation \cite{open-data-census}
and Code for America \cite{open-data-census-us}
conducted open data censuses to determine which governments were
releasing what data publically on the internet. The two studies
focused on a few datasets (11 for the former, 17 for the latter)
whose public release they deemed especially important; these datasets
included budgets, laws, and procurement contracts.
In each case, volunteers searched the internet and talked to
government employees in order to determine whether each dataset was
available. When datasets were available, volunteers recorded some
metadata about the dataset and rated how well the data were published
based on a data availability rubric.

As slow as it may be, a crude approach like this one is feasible and
worthwhile when we are very focused with our goals.

\subsection{Use standard metaformats}
Many groups develop domain-specific metaformats for expressing a very specific
sort of data. For example, JSON API is a metaformat for expressing the
response of a database query on the web \cite{jsonapi}, Data Packages is a
metaformat for expressing metadata about a dataset \cite{datapackages},
and KML is a metaformat for expressing annotations of geographic maps \citep{kml}.
% http://portal.opengeospatial.org/files/?artifact_id=27810
% http://dataprotocols.org/data-packages/
% http://jsonapi.org/
% http://www.opengeospatial.org/standards/is

Agreement on format and metaformat makes it faster and easier to inspect
individual files. On the other hand, it does not alleviate the
need to acquire lots of different files and to at least glance at them.
We spend less time manually inspecting each dataset, but we must still
manually inspect lots of dataset.

The same sort of thing happens when data publishers provide graphs of
each individual dataset. When we provide some graphs of a dataset
rather than simply the standard data file, we are trying to make it easier for
people to understand that particular dataset, rather than trying to focus
them on a particular subset of datasets.

\subsection{Provide good metadata} \label{guidelines}
Data may be easier to find if we catalog our data well and adhere to
certain data quality standards. With this reasoning,
many "open data" guidelines provide direction as to how a person
or organization with lots of datasets might allow other people
to use them.
\cite{open-data-census,fivestars,sunlight,sebastopol,odi}

At a basic level, these guidelines suggest that data should
be available on the internet and under a free license; at the other
end of the spectrum, guidelines suggest that data be in standard
formats accompanied with particular metadata.

Datasets can be a joy to work with when these data quality guidelines
are followed, but this requires much upfront work by the publishers
of the data.

\subsection{Asking people}
In practice, I find that people learn what's in a spreadsheet through word
of mouth, even if the data are already published on the internet in standard
formats with good metadata.

* Advertising the publication of data
* Amanda's list
* Conference talks on publication of data

Amanda Hickman teaches journalism and keeps a list of data sources for her
students. \cite{amanda}
https://github.com/amandabee/cunyjdata/wiki/Where-to-Find-Data

There are even entire conferences about the contents of newly released datasets
% http://apdu.org/events/conference/apdu-2013/
\cite{apdu}

\section{How I acquire lots of spreadsheets} \label{acquire}
In order to explore methods for examining thousands of spreadsheets,
I needed to find spreadsheets that I could explore.

Many governments and other large organizations publish spreadsheets on
data catalog websites.
Data catalogs make it kind of easy to get a bunch of spreadsheets all together.
The basic approach is this.

\begin{enumerate}
\item Download a list of all of the dataset identifiers that are present in the data catalog.
\item Download the metadata document about each dataset.
\item Download data files about each dataset.
\end{enumerate}

I've implemented this for the following data catalog softwares.

\begin{itemize}
\item Socrata Open Data Portal
\item Common Knowledge Archive Network (CKAN)
\item OpenDataSoft
\end{itemize}

This allows me to get all of the data from most of the open data catalogs I know about.

Most of these spreadsheets are represented as data tables,
where rows correspond to records and columns correspond to variables. \cite{table}

After I've downloaded spreadsheets and their metadata,
I often assemble them into a spreadsheet about spreadsheets. \cite{data-driven}
In this super-spreadsheet, each record corresponds to a full
sub-spreadsheet; you could say that I am collecting features or statistics
about each spreadsheet.

\section{Crude statistics about spreadsheets}
My first approach was involved running rather crude analyses on this
interesting dataset-about-datasets that I had assembled.

\subsection{How many datasets}
![Plot of dataset counts by site](/dada/socrata-summary/figure/big_portals_datasets.png)

\subsection{Meaninglessness of the count of datasets}

Many organizations report this count of datasets that they publish, and this number
turns out to be nearly useless.

> **Column names**: "grade", "year", "demographic", "number_tested", "mean_scale_score", "num_level_1", "pct_level_1", "num_level_2", "pct_level_2", "num_level_3", "pct_level_3", "num_level_4", "pct_level_4", "num_level_3_and_4", "pct_level_3_and_4"
>
> **Datasets with these column names**:
>
> * [Math Test Results 2006-2012 - Citywide - Gender](https://data.cityofnewyork.us/d/2bh6-qmgg)
> * [Math Test Results 2006-2012 - Citywide - Ethnicity](https://data.cityofnewyork.us/d/vve2-26rs)
> * [English Language Arts (ELA) Test Results 2006-2012 - Citywide - SWD](https://data.cityofnewyork.us/d/d72n-ivax)
> * [English Language Arts (ELA) Test Results 2006-2012 - Citywide - ELL](https://data.cityofnewyork.us/d/72db-huua)
> * [Math Test Results 2006-2012 - Citywide - SWD](https://data.cityofnewyork.us/d/ufu7-zp25)
> * [English Language Arts (ELA) Test Results 2006-2012 - Citywide - All Students](https://data.cityofnewyork.us/d/89di-hi4s)
> * [Math Test Results 2006-2012 - Citywide - ELL](https://data.cityofnewyork.us/d/ngbi-cq85)
> * [English Language Arts (ELA) Test Results 2006-2012 - Citywide - Gender](https://data.cityofnewyork.us/d/cs9m-cz6f)
> * [Math Test Results 2006-2012 - Citywide - All Students](https://data.cityofnewyork.us/d/fxwm-3t4n)
> * [English Language Arts (ELA) Test Results 2006-2012 - Citywide - Ethnicity](https://data.cityofnewyork.us/d/p5w7-g72z)

These "datasets" can all be thought of as subsets of the same single dataset.
If I just take different subsets of a single spreadsheet (and optionally
pivot/reshape the subsets), I can easily expand one spreadsheet into over 9000.

\subsection{Downloads of datasets}
So maybe we should look at other things too.
Socrata Open Data Portal software provides a number for
how many times people have downloaded each dataset.
So how many have people downloaded these datasets?

![Plot of dataset counts and download counts by site](/dada/socrata-summary/figure/big_portals_density_text.png)

Here, the x axis is the same as the previous plot but the y axis is the total
downloads by site.

\subsection{Size of the datasets}
I can also look at how big they are.
It turns out that most of them are pretty small.

%   s <- read.csv('~/t/socrata-analysis/socrata-deduplicated.csv')
%   sum(is.na(s$nrow))                                                                                                  
% [1] 476
%   mean(s$nrow > 100, na.rm = T)                                                                                       
% [1] 0.2507369
%   mean(s$nrow > 1000, na.rm = T)                                                                                      
% [1] 0.1162797
%   mean(s$nrow > 10000, na.rm = T)                                                                                     
% [1] 0.05230904
%   mean(s$nrow > 100000, na.rm = T)                                                                                    
% [1] 0.01799659

Regardless of the format of these datasets, you can think of them as
spreadsheets without code, where columns are variables and rows are records.
In Socrata catalogs as of last summer,

* Only 25% of datasets had more than 100 rows.
* Only 12% of datasets had more than 1,000 rows.
* Only 5% of datasets had more than 10,000 rows.



\subsection{Derived datasets}
The Socrata product allows the public to write queries on datasets and
save them publically as new datasets. Aside from inflating the number
of datasets, making it hard to distinguish between official data and
unofficial queries on official data, and complicating the various
statistics about each dataset, this allows us to see how people are
querying datasets.


XXX image of families




\section{Measuring how well different spreadsheets follow data publishing guidelines}
Having gotten some feel for the contents of these various data catalogs,
I started running some less arbitrary statistics.
As discussed in section \ref{guidelines}, many groups have written guidelines
as to how data should be published.
\cite{open-data-census,fivestars,sunlight,sebastopol,odi}
I started coming up with measures of adherence to these guidelines and running
them across all of these datasets.










\section{Searching for spreadsheets}
I noticed that it's very hard to find spreadsheets that are relevant
to a particular analysis unless you already know that the spreadsheet exists.
Major search engines focus on HTML format web pages, and spreadsheet files
are often not indexed at all.

The various data catalog software programs
discussed in section \ref{acquire} include a search feature, but this feature
only works within the particular website. For example, I have to go to the
Dutch government's data catalog website in order to search for Dutch data.

I see two main issues in the common means of searching through spreadsheets.
The first issue is that the search method is quite naive; these websites are
usually running crude keyword searches.

The second issue is that the search is localized to datasets that are published
or otherwise managed by a particular entity; it's hard to search for
spreadsheets without first identifying a specific publisher or repository.

Here's another issue with using website-specific search bars.
When I'm looking for spreadsheets, the publishing organization is unlikely
to be my main concern. For example, if I'm interested in data about the
composition of different pesticides, but I don't really care whether the
data were collected by this city government or by that country government.

In my view, we can have one set of tools/people that focus on making
data available in a crude form and another set for assembling these crude
data into something more relevent to the people who want the data

[![](/dada/openprism/taco.png)](http://openprism.thomaslevine.com)

And that's why I made OpenPrism. This is a disgustingly simple site that
forwards your search query to 100 other sites that house spreadsheets.

Let me reiterate my thoughts on searching spreadsheets.

> Why searching for spreadsheets is hard
> ==========================================
>
> * Naive search method
> * Site-specific search


I started to address the first issue by pulling schema-related features out
of the spreadsheets, and I started to address the second issue by letting
people search many sites at once. Taking this further, I've been thinking
about what it would mean to have a search engine for spreadsheets.

![](wordsearch.png)

When we search for ordinary written documents, we send words into a search
engine and get pages of words back.

![](commasearch.png)

What if we could search for spreadsheets
by sending spreadsheets into a search engine and getting spreadsheets back?
The order of the results would be determined by various specialized statistics;
just as we use PageRank to find relevant hypertext documents, we can develop
other statistics that help us find relevant spreadsheets.

So now I'm looking for ways to do interesting searches on spreadsheets.

> Rows and columns

I think a lot about rows and columns. When we define tables in relational
databases, we can say reasonably well what each column means, based on
names and types, and what a row means, based on unique indices.
In spreadsheets, we still have column names, but we don't get everything
else.

The unique indices tell us quite a lot; they give us an idea about the
observational unit of the table and what other tables we can nicely
join or union with that table. So I made a package that finds unique
indices in ordinary CSV files.

    pip3 install special_snowflake

It's called "special snowflake", but it needs a better name.

If we pass the iris dataset to it, ::

    "Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species"
    5.1,3.5,1.4,0.2,"setosa"
    4.9,3,1.4,0.2,"setosa"
    4.7,3.2,1.3,0.2,"setosa"
    4.6,3.1,1.5,0.2,"setosa"
    ...

we get no unique keys ::

    >>> special_snowflake.fromcsv(open('iris.csv'))                                                                  
    set()

because no combination of columns uniquely identifies the rows.
Of course, if we add an identifier column, ::

    "Id","Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species"
    1,5.1,3.5,1.4,0.2,"setosa"
    2,4.9,3,1.4,0.2,"setosa"
    3,4.7,3.2,1.3,0.2,"setosa"
    4,4.6,3.1,1.5,0.2,"setosa"
    ...

that one gets returned. ::

    >>> special_snowflake.fromcsv(open('iris.csv'))                                                                  
    {('Id',)}

For a more interesting example, let's look at chickweight.

    "weight","Time","Chick","Diet"
    42,0,"1","1"
    51,2,"1","1"
    59,4,"1","1"
    64,6,"1","1"
    76,8,"1","1"
    ...

I could read the documentation on this dataset and tell you
what its statistical unit is (`?ChickWeight` in R), or I could
just let `special_snowflake` figure it out for me.

    >>> special_snowflake.fromcsv(open('chick.csv'))
    {('Time', 'Chick')}

The statistical unit is chicks in time. That is, something was
observed across multiple chick, and multiple observations were
taken from each (well, at least one) chick.

Some spreadsheets are have less obvious identifiers. In this
table of 1219 rows and 33 columns,

    >>> from urllib.request import urlopen
    >>> url = 'http://data.iledefrance.fr/explore/dataset/liste-des-points-de-contact-du-reseau-postal-dile-de-france/download/?format=csv'
    >>> fp = urlopen(url)
    >>> special_snowflake.fromcsv(fp, delimiter = ';')
    {('adresse', 'code_postal'),
     ('adresse', 'localite'),
     ('identifiant',),
     ('libelle_du_site',),
     ('wgs84',)}

we find five functional unique keys. Just by looking at the column names,
I'm gussing that the first two are combinations of parts of the postal address
and that the latter three look are formal identifiers.
And when I do things correctly and look at the
[data dictionary](http://data.iledefrance.fr/api/datasets/1.0/liste-des-points-de-contact-du-reseau-postal-dile-de-france/attachments/laposte_description_champs_pointdecontact_pdf/),
I come to the same interpretation.

This tells me that this dataset is about postal service locations,
with one location per row. It also gives me some ideas as to things that can
act as unique identifiers for postal service locations.

It's kind of cool to run this on individual spreadsheets, but it's even cooler
to run this on lots of spreadsheets.
In [blizzard](https://pypi.python.org/pypi/blizzard), I find spreadsheets with
the same unique indices, and then I look for overlap between those spreadsheets.

![](network.png)

Let's now trace what happens when we compare one spreadsheet to our database
of spreadsheets.

    # This is the one missing slide;
    # I'll fill it in once I make this thing easier to query.

Spreadsheets with high overlap might be good to join to each other, and
spreadsheets with low overlap might be good to union with each other.

All of this is quite crude at the moment, so I'm somewhat surprised that
anything interesting comes out.

## Review
I've been downloading lots of spreadsheets and doing crude, silly things
with them.

![](/dada/zombie-links/figure/p_prop_links.png)

I started out by looking at very simple things like how big they are.
I also tried to quantify other people's ideas of how good datasets are,
like whether they are up-to-date and whether they are freely licensed.

> ???
> ====

The main thing that I keep seeing is that nobody has any idea what's in all
of these spreadsheets; I notice this because people continue to be interested
in results that I find pretty boring.

> "Search"

Part of this is that it's pretty hard to search for spreadsheets.

The first issue is that you need to type your search into multiple search
bars. Dedicated search engines like DuckDuckGo don't index all of the
spreadsheets, so you're stuck using site-specific searches, and these only
search within their specific sites.

[![](/dada/openprism/taco.png)](http://openprism.thomaslevine.com)

I wrote OpenPrism to deal with this; you type your search into one search
bar, and it's as if you typed it in to all of the data catalogs I know about
at once.

The other issue is that our methods for searching spreadsheets are quite naive.
Most of these data catalogs look for exact string matches in the datasets or
for something similarly crude.

![](wordsearch.png)

The way we look up information today is to type some words into a search engine
and read the first few results. Why is that not the way we look up data?

We have designed search engines to look for things arranged in paragraphs
and sections and pages and hyperlinks; we haven't designed search engines for
things with tables and rows and columns and join keys.
PageRank is hailed as the magical invention that
fixed web search, but it depends on hyperlinks, so doesn't help much with spreadsheets.

![](commasearch.png)

The search engine for spreadsheets is going to look a bit different from
the search engine for words.















\section{Findings}
Here are some of the things I've found by looking at lots of spreadsheets at
once. I think of them as ways of automating some of the early steps in data
analysis, but I'm packaging them into the three categories I mentioned above
(looking for datasets, dealing with metadata problems, and quantifying quality).

\subsection{New ways of looking for datasets}
We search for prose by typing prose into a search bar; why don't
we search for spreadsheets by typing spreadsheets into a search bar?
Spreadsheets are much more structured than arbitrary prose, and we
can use this structure to enable new search paradigms. We could search
for things like the following.

\begin{itemize}
\item Spreadsheets that were produced by the same program as another spreadsheet
\item Spreadsheets that I can join to a particular spreadsheet
\item Spreadsheets with a particular statistical unit
\item Spreadsheets in long format (rather than wide format)
\end{itemize}

One example is the detection of spreadsheets that can be stacked on top of
each other (unioned).
My work on this started with AppGen,\cite{appgen} which was a system to
generate random apps based on randomly combined datasets. I combined spreadsheets
by matching spreadsheets with the same column headers.

Spreadsheets with the same column headers seemed to be semantically related to
each other. For example, there were 23 spreadsheets with these same columns.
\begin{itemize}
\item type\_of\_abuse\_of\_authority\_allegation
\item substantiated\_number
\item sunstantiated\_rate
\item exonerated\_number
\item exonerated\_rate
\item unsubstantiated\_number
\item unsubstantiated\_rate
\item unfounded\_number
\item unfounded\_rate
\item officer\_unidentified\_number
\item officer\_unidentified\_rate
\item miscellaneous
\item miscellaneous\_rate
\end{itemize}

All of these spreadsheets were uploaded by the same person, and they all had
titles of the form ``\$\{crime\} Allegations \$\{year\}'', such as
``Disposition Of Force Allegations 2006''.

When we organize spreadsheets by their column headers, groups of related
spreadsheets pop out at us.

\subsection{Dealing with incomplete metadata}
People complain about how data are bad and metadata are bad. Rather than
fixing it on a case-by-case basis, I think we should just come up with ways
of dealing with it. As an example, let's talk about unique identifiers.

I don't know of anyone who specifies within a spreadsheet file which columns
should be unique. There are methods with external metadata files, such as data
packages \cite{datapackages}, but hardly anyone uses those either. Rather than
trying to get people to write down which columns are unique, we can just figure
it out for ourselves.

special\_snowflake \cite{specialsnowflake} is a package that does just that.
It looks at all combinations of columns within a particular spreadsheet and
determines which combinations function as unique identifiers.

With tools like special\_snowflake, we don't have to rely as much on other
people for the creation of accurate metadata; we can lazily figure out the
metadata ourselves.

\subsection{Quantifying data quality}
A bunch of people \cite{open-data-census,fivestars,sunlight,sebastopol,odi}
have come up with relatively qualitative guidelines for publishing data.

I've been exploring ways of assigning numbers to represent data quality.
Using only the simple metadata files from open data catalogs, I've come up
with automated approaches for describing the updating, \cite{updatedness}
licensing, \cite{licensing} size \cite{summary}, file format \cite{file-formats}
and availability \cite{dead,zombie} of groups of datasets.

By quantifying these guidelines about data quality, we can more quickly and
precisely assess data quality.

\section{Applications}
A couple of people can share a few spreadsheets without any special means,
but it gets hard when there are more than a couple people sharing more than
a few spreadsheets. In my research, I'm coming up with approaches for assisting
this sharing.

Software for the publishing and analysis of data can integrate new search
paradigms to assist people in finding relevant datasets or enriching existing
datasets.

The ubiquitous and persistent complaint of bad metadata can be tempered through
the use of tools that infer metadata or provide alternative search strategies;
by becoming more robust to bad metadata, we make available a broader range of
datasets.

Quantification of the quality of data can be helpful to those who are tasked
with cataloging and maintaining a diverse array of datasets. Data quality
statistics provide a quick and timely summary of the issues with different
datasets and allow for a more targeted approach in the maintenance of a
data catalog.

\section{Future}
Many people say that releasing open data will create transparency in government,
engage citizens in their governments, and stimulate the economy. This all seems
reasonable, but I haven't seen much empirical research that suggests that the
sharing of data affects any of these outcomes.

As I come up with more ways of computationally describing datasets, I am becoming
more able to apply various quantitative analyses to the dataset of datasets;
this is starting to enable weaker versions of the aforementioned measure of
outcomes. It would be nice to know whether releasing your organization's data on
the internet will get people to use them.

\bibliographystyle{abbrv}
\bibliography{spreadsheets}
\balancecolumns
\end{document}
