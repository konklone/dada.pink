---
title: Data set as Data point
---
<!-- For the winter issue of Socrata's magazine -->
I've recently been collecting and studying
[data about open data](/open-data).

## Data set as data point
The main inspiration for all of these studies is the idea that
any collection of things could be seen as data to be analyzed.

Specifically, even a collection of datasets could be treated
as a dataset of datasets, with a record for each particular
dataset.

## Metadata as data
The term "metadata" is sort of funny. Metadata are data about
data, but they're still data, so do we really need another term
for it? In studying metadata about 100,000 datasets, I started
to see what it means.

When people talk about "metadata", they're
usually thinking of stuff that you'd use for cataloging
and framing the data rather than stuff on which you would do
"data analysis". That is, metadata are things that you would use
for styling webpages, titling graphs, and searching datasets,
but you would never put them in a spreadsheet.
Of course, it doesn't have to be this way.

When we see datasets as data points, we see metadata as data.
Inside of our collection of datasets, we have a record for each
sub-dataset, and this record is composed of metadata about that
sub-dataset.

## Why this matters: Data-driven open data
Ironically, our open data
initiatives haven't been particularly data-driven. I've seen a
[lot](http://beyondtransparency.org/)
[of](http://www.socrata.com/case-studies/)
[case](http://ckan.org/case-studies/)
[studies](http://theodi.org/case-studies)
about how to open government data, but these are based strongly
on personal experience about opening data rather than being based
more on precise, quantitative data about opening data.

I've seen [comparatively little](/open-data) work that uses data
about open data efforts to come up with guidelines or
decisions about the opening of data. Similarly, standard
data-driven features like randomized experiments (A/B testing)
and recommender systems aren't implemented in any data catalog
software that I've seen. We are releasing lots of open data and
producing data about our release of data, but we aren't taking
advantage of these data to figure out how to make open data better.

## Conclusion
Open data portals make it easier to consume data once someone
has decided to publish them, but they don't yet give us the
bigger picture of what's going on inside an open data initiative.
We can't really tell what datasets are available, who's using them,
what impact they're having, or whether they are of good quality.

We need to give data publishers and data consumers a better picture
of what is going on in open data portals. I don't know how we'll do
that, but I think we'll get somewhere if we start thinking of datasets
as datapoints.
